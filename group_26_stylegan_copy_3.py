# -*- coding: utf-8 -*-
"""Group 26 StyleGAN copy 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NCaHuKhuyxTrgf9Y0sLR7LMLUm0d4XnM
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from google.colab import drive
from PIL import Image
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from scipy.linalg import sqrtm
import joblib
import pickle
drive.mount('/content/drive')

# Constants
LATENT_DIM = 512
IMG_SIZE = 512
CHANNELS = 3
BATCH_SIZE = 8
EPOCHS = 400

dataset_directory = '/content/drive/MyDrive/AI_stuff/stylegan/images'

# Function to display images
def display_images(dataset_directory, images_num=5):
    image_files = [f for f in os.listdir(dataset_directory) if f.endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif'))]
    num_images = min(images_num, len(image_files))
    fig, axes = plt.subplots(1, num_images, figsize=(20, 20), dpi=100)
    for i in range(num_images):
        img_path = os.path.join(dataset_directory, image_files[i])
        img = Image.open(img_path)
        axes[i].imshow(img)
        axes[i].set_title(f'Image {i+1}')
        axes[i].axis('off')
    plt.show()

display_images(dataset_directory, images_num=5)

# Mapping Network
#Input Layer
def mapping_network(latent_dim, num_layers=8):
    model = tf.keras.Sequential()
    model.add(layers.InputLayer(input_shape=(latent_dim,)))
    for _ in range(num_layers):
        model.add(layers.Dense(latent_dim, activation='relu'))
    return model

# AdaIN Layer
class AdaIN(layers.Layer):
    def __init__(self, channels):
        super(AdaIN, self).__init__()
        self.channels = channels
        self.epsilon = 1e-7

    def build(self, input_shape):
        self.scale_transform = layers.Dense(self.channels)
        self.bias_transform = layers.Dense(self.channels)

    def call(self, x, w):
        mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)
        std = tf.math.reduce_std(x, axis=[1, 2], keepdims=True)
        normalized = (x - mean) / (std + self.epsilon)

        style_scale = self.scale_transform(w)
        style_bias = self.bias_transform(w)

        style_scale = tf.reshape(style_scale, (-1, 1, 1, self.channels))
        style_bias = tf.reshape(style_bias, (-1, 1, 1, self.channels))

        return style_scale * normalized + style_bias

# Generator
def build_generator(latent_dim, img_size, channels):
    input_latent = layers.Input(shape=(latent_dim,))
    w = mapping_network(latent_dim)(input_latent)

    x = layers.Dense(4 * 4 * 512)(w)
    x = layers.Reshape((4, 4, 512))(x)

    for i in range(int(np.log2(img_size) - 2)):
        x = layers.Conv2D(512, (3, 3), padding='same')(x)
        x = layers.LeakyReLU()(x)
        x = AdaIN(512)(x, w)
        x = layers.UpSampling2D()(x)

    x = layers.Conv2D(channels, (3, 3), padding='same', activation='tanh')(x)
    generator = tf.keras.models.Model(input_latent, x)
    return generator

# Discriminator
def build_discriminator(img_size, channels):
    input_img = tf.keras.layers.Input(shape=(img_size, img_size, channels))
    x = input_img

    for i in range(5):
        x = layers.Conv2D(64 * (2 ** i), (3, 3), padding='same')(x)
        x = layers.LeakyReLU(alpha=0.2)(x)
        x = layers.Dropout(0.3)(x)  # Added dropout for regularization
        if i % 2 == 0:
            x = layers.AveragePooling2D(pool_size=(2, 2))(x)

    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)

    model = tf.keras.models.Model(input_img, x)
    return model

# Loss Functions
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    return real_loss + fake_loss

# Optimizers
generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)  # Adjusted beta_1
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)  # Adjusted beta_1

# Build Models
generator = build_generator(LATENT_DIM, IMG_SIZE, CHANNELS)
discriminator = build_discriminator(IMG_SIZE, CHANNELS)

# Load and preprocess dataset
def load_images_from_folder(folder_path, img_size):
    images = []
    for filename in os.listdir(folder_path):
        img = load_img(os.path.join(folder_path, filename), target_size=(img_size, img_size))
        if img is not None:
            img = img_to_array(img)
            img = (img - 127.5) / 127.5  # Normalize to [-1, 1]
            images.append(img)
    return np.array(images)

images = load_images_from_folder(dataset_directory, IMG_SIZE)
train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(len(images)).batch(BATCH_SIZE)

@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss

# Load the InceptionV3 model
inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))

# FID calculation function
def calculate_fid(real_images, generated_images):
    real_images = tf.image.resize(real_images, (299, 299)).numpy()
    generated_images = tf.image.resize(generated_images, (299, 299)).numpy()

    real_images = preprocess_input(real_images)
    generated_images = preprocess_input(generated_images)

    act1 = inception_model.predict(real_images)
    act2 = inception_model.predict(generated_images)

    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)
    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)

    ssdiff = np.sum((mu1 - mu2)**2.0)
    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)
    if np.iscomplexobj(covmean):
        covmean = covmean.real

    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)
    return fid

# Generate and Save Images
def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training=False)
    fig = plt.figure(figsize=(4, 4))

    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i + 1)
        plt.imshow((predictions[i] + 1) / 2)  # Rescale [-1, 1] to [0, 1]
        plt.axis('off')

    plt.savefig(f'image_at_epoch_{epoch:04d}.png')
    plt.show()

# Training loop with FID evaluation
def train(dataset, epochs):
    for epoch in range(epochs):
        for image_batch in dataset:
            gen_loss, disc_loss = train_step(image_batch)

        print(f'Epoch {epoch+1}, Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}')

        if (epoch + 1) % 10 == 0:
            generate_and_save_images(generator, epoch + 1, seed)

            # Generate images for FID evaluation
            noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])
            generated_images = generator(noise, training=False)
            fid = calculate_fid(images[:BATCH_SIZE], generated_images)
            print(f'FID score at epoch {epoch+1}: {fid}')

# Main Execution
NUM_EXAMPLES_TO_GENERATE = 16
seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, LATENT_DIM])

# Start training
train(train_dataset, EPOCHS)

# Define the path where you want to save the models
model_save_path = '/content/drive/My Drive/StyleGAN_Models/'

# Save the models
generator.save(model_save_path + 'generator_model.h5')
discriminator.save(model_save_path + 'discriminator_model.h5')

print("Models saved to Google Drive.")

# Create a pickle file for the generator model
with open(model_save_path + 'generator_model.pkl', 'wb') as f:
    pickle.dump(generator, f)

# Create a pickle file for the discriminator model
with open(model_save_path + 'discriminator_model.pkl', 'wb') as f:
    pickle.dump(discriminator, f)

print("Models saved to Google Drive and as pickle files.")

